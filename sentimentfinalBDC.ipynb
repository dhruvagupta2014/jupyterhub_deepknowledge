{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading required packages:\n",
    "#### sklearn: package which has functions used to perform machine learning \n",
    "#### nltk: package used to perform natural language processing\n",
    "#### pandas: package used to read and write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying stop words into stop object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a stemmer object to extract root words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dhruva.gupta\\\\Downloads'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n",
      "(4086, 11)\n",
      "My wife took me here on my birthday for breakfast and it was excellent.  The weather was perfect which made sitting outside overlooking their grounds an absolute pleasure.  Our waitress was excellent and our food arrived quickly on the semi-busy Saturday morning.  It looked like the place fills up pretty quickly so the earlier you get here the better.\r\n",
      "\r\n",
      "Do yourself a favor and get their Bloody Mary.  It was phenomenal and simply the best I've ever had.  I'm pretty sure they only use ingredients from their garden and blend them fresh when you order it.  It was amazing.\r\n",
      "\r\n",
      "While EVERYTHING on the menu looks excellent, I had the white truffle scrambled eggs vegetable skillet and it was tasty and delicious.  It came with 2 pieces of their griddled bread with was amazing and it absolutely made the meal complete.  It was the best \"toast\" I've ever had.\r\n",
      "\r\n",
      "Anyway, I can't wait to go back!\n"
     ]
    }
   ],
   "source": [
    "# read yelp.csv into a DataFrame\n",
    "\n",
    "yelp = pd.read_csv(\"yelp.csv\",encoding = \"ISO-8859-1\")\n",
    "print(yelp.shape)\n",
    "yelp.head()\n",
    "\n",
    "\n",
    "#X.apply(lambda x: [item for item in x.split() if item not in stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame that only contains the 5-star and 1-star reviews\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]\n",
    "print(yelp_best_worst.shape)\n",
    "# define X and y\n",
    "X = yelp_best_worst.text\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words:\n",
    "Some examples of stop words are: \"a\", \"and\", \"but\", \"how\", \"or\", and \"what.\" While the majority of all Internet search engines utilize stop words, they do not prevent a user from using them, but they are ignored.\n",
    "\n",
    "### Stemming:\n",
    "A stemmer for English, for example, should identify the string \"cats\" (and possibly \"catlike\", \"catty\" etc.) as based on the root \"cat\", and \"stems\", \"stemmer\", \"stemming\", \"stemmed\" as based on \"stem\". A stemming algorithm reduces the words \"fishing\", \"fished\", and \"fisher\" to the root word, \"fish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =X.apply(lambda x: ' '.join([item for item in x.split() if item not in stop])) #removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My wife took birthday breakfast excellent. The weather perfect made sitting outside overlooking grounds absolute pleasure. Our waitress excellent food arrived quickly semi-busy Saturday morning. It looked like place fills pretty quickly earlier get better. Do favor get Bloody Mary. It phenomenal simply best I\\'ve ever had. I\\'m pretty sure use ingredients garden blend fresh order it. It amazing. While EVERYTHING menu looks excellent, I white truffle scrambled eggs vegetable skillet tasty delicious. It came 2 pieces griddled bread amazing absolutely made meal complete. It best \"toast\" I\\'ve ever had. Anyway, I can\\'t wait go back!'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0] #after removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem1(text1):\n",
    "    return ps.stem(text1)\n",
    "\n",
    "X=X.apply(stem1)\n",
    "\n",
    "y = yelp_best_worst.stars\n",
    "\n",
    "# split the new DataFrame into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my wife took birthday breakfast excellent. the weather perfect made sitting outside overlooking grounds absolute pleasure. our waitress excellent food arrived quickly semi-busy saturday morning. it looked like place fills pretty quickly earlier get better. do favor get bloody mary. it phenomenal simply best i\\'ve ever had. i\\'m pretty sure use ingredients garden blend fresh order it. it amazing. while everything menu looks excellent, i white truffle scrambled eggs vegetable skillet tasty delicious. it came 2 pieces griddled bread amazing absolutely made meal complete. it best \"toast\" i\\'ve ever had. anyway, i can\\'t wait go back!'"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 2, 1, 1, 0, 1, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cveg = CountVectorizer()\n",
    "\n",
    "x_example = cveg.fit_transform([\"how are you\", \"We are are fine\", \"are we fine\", \"yes we are fine\",\"who is she where is the car\"])\n",
    "x_example.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are',\n",
       " 'car',\n",
       " 'fine',\n",
       " 'how',\n",
       " 'is',\n",
       " 'she',\n",
       " 'the',\n",
       " 'we',\n",
       " 'where',\n",
       " 'who',\n",
       " 'yes',\n",
       " 'you']"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cveg.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer transformation example for one hot encoding\n",
    "\n",
    "|are | fine | how | we | yes | you |        \n",
    "| :- |: | :| :|: | : \n",
    "|1| 0  | 1 | 0 | 0 | 1 \n",
    "|2| 1  | 0 | 1 | 0 | 0 \n",
    "|1| 1  | 0 | 1 | 0 | 0 \n",
    "|1| 1  | 0 | 1 | 1 | 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "vect = CountVectorizer()\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.toarray()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply logistic regression for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9246575342465754\n"
     ]
    }
   ],
   "source": [
    "# use logistic regression with text column only\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(X_train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(X_test_dtm)\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022,)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ii = np.where(y_pred_class == 5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[150,  34],\n",
       "       [ 43, 795]], dtype=int64)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= confusion_matrix(y_test,y_pred_class )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150  34]\n",
      " [ 43 795]]\n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
